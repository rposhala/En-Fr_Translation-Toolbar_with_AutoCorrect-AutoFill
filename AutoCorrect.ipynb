{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoCorrect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MM6D8SE-jlfo6TyjUwNE7LajQ6kuR6YC",
      "authorship_tag": "ABX9TyNZFN2ipc3zRa9ggarY32GT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rposhala/En-Fr_Translation-Toolbar_with_AutoCorrect-AutoFill/blob/AutoCorrect/AutoCorrect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQJivz4HyZV2"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_GX9IJdyeQ-"
      },
      "source": [
        "def process_data(file_name):\n",
        "    words = []\n",
        "    with open(file_name) as f:\n",
        "        read_file = f.read()\n",
        "        for line in read_file.lower().split('\\n'):\n",
        "            words += re.findall(r'\\w+', line)\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGJtN7-W11sZ",
        "outputId": "72d23b92-0517-4a14-d39b-16199aaafd80"
      },
      "source": [
        "# I used my google drive manage the dataset\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/MyDrive/Colab Notebooks/NLP_Specialization\")\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "AutoCorrect.ipynb\tfr_embeddings.p\n",
            "Course2-NLPProbModels\tGoogleNews-vectors-negative300.bin\n",
            "en_embeddings.p\t\tGoogleNews-vectors-negative300.bin.gz\n",
            "en-fr.test.txt\t\tNLP_with_Classification_and_Vector_Spaces\n",
            "en-fr.train.txt\t\tshakespeare.txt\n",
            "En-Fr-Translator.ipynb\twiki.multi.fr.vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxJO6xLlyeJ5",
        "outputId": "12841c28-8fa0-4973-8bfb-3117806224c2"
      },
      "source": [
        "word_l = process_data('./shakespeare.txt')\n",
        "vocab = set(word_l)\n",
        "print(\"The first ten words in the text are: \", word_l[0:10])\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first ten words in the text are:  ['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6116 unique words in the vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la6c96Ws2Ae-"
      },
      "source": [
        "def get_count(word_l):\n",
        "    word_count_dict = {}\n",
        "    word_count_dict = Counter(word_l)\n",
        "    return word_count_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V2WdHAR2AcW",
        "outputId": "78fb0ce0-e2f5-482f-fd6b-959467c0f0e0"
      },
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(\"There are \",len(word_count_dict),\" key values pairs\")\n",
        "print(\"The count for the word 'thee' is \",word_count_dict.get('thee',0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are  6116  key values pairs\n",
            "The count for the word 'thee' is  240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mliqdbuq2AWx"
      },
      "source": [
        "def get_probs(word_count_dict):\n",
        "    probs = {}    \n",
        "    total = sum([i for i in word_count_dict.values()])\n",
        "    for k, v in word_count_dict.items():\n",
        "        probs[k] = v/total\n",
        "\n",
        "    return probs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1-UhIpJ2zhp",
        "outputId": "746a3e00-3c0a-4be7-b1bf-12ca7a97e17a"
      },
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['thee']:.4f}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of probs is 6116\n",
            "P('thee') is 0.0045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOvGjxv25jG"
      },
      "source": [
        "<a name='2'></a>\n",
        "## String Manipulations\n",
        "\n",
        "Now, that you have computed $P(w_i)$ for all the words in the corpus, you will write a few functions to manipulate strings so that you can edit the erroneous strings and return the right spellings of the words. In this section, you will implement four functions: \n",
        "\n",
        "* delete_letter: given a word, it returns all the possible strings that have **one character removed**. \n",
        "* switch_letter: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
        "* replace_letter: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
        "* insert_letter: given a word, it returns all the possible strings that have an **additional character inserted**. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6v_-Lr253S"
      },
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "\n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "    delete_l = [s1+s2[1:] for s1, s2 in split_l]\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return delete_l"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u34HL0r23XXe",
        "outputId": "78c05a3f-4bcb-497e-8b43-c290ebbec10b"
      },
      "source": [
        "delete_word_l = delete_letter(word=\"cans\",\n",
        "                        verbose=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word cans, \n",
            "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
            "delete_l = ['ans', 'cns', 'cas', 'can']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWogcQGY3fwG"
      },
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    \n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "    switch_l = [s1+s2[1]+s2[0]+s2[2:] for s1, s2 in split_l if len(s2) > 1]\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
        "\n",
        "    return switch_l"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCYJ5Agm3mXv",
        "outputId": "f79ba476-7853-4ef0-da0e-0a95f1a5830f"
      },
      "source": [
        "switch_word_l = switch_letter(word=\"eta\", verbose=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = eta \n",
            "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
            "switch_l = ['tea', 'eat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI9N0N6d3str"
      },
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "    replace_set = set(s1+i+s2[1:] for s1, s2 in split_l for i in letters if s1+i+s2[1:] != word)\n",
        "    \n",
        "    replace_l = sorted(list(replace_set))\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
        "    \n",
        "    return replace_l"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz7R2t8A3tau",
        "outputId": "a9340a0e-e80f-40aa-f4bd-ce475079a6f3"
      },
      "source": [
        "replace_l = replace_letter(word='can',\n",
        "                              verbose=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = can \n",
            "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
            "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFnFpkF63teC"
      },
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    insert_l = [s1+i+s2 for s1, s2 in split_l for i in letters]\n",
        "    \n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "    \n",
        "    return insert_l"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-q4vwd73tjb",
        "outputId": "aa280ddd-3181-43ca-fd7d-88f331f959db"
      },
      "source": [
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word at \n",
            "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
            "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
            "Number of strings output by insert_letter('at') is 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZvVgKAN4BKy"
      },
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \n",
        "    edit_one_set = set()\n",
        "    \n",
        "    edit_one_set = edit_one_set.union(set(delete_letter(word)+replace_letter(word)+insert_letter(word)))\n",
        "    if allow_switches:\n",
        "        edit_one_set = edit_one_set.union(set(switch_letter(word)))\n",
        "    \n",
        "    return edit_one_set"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snFRbkNJ4BID",
        "outputId": "7593edde-f123-4d68-fff1-cd68d89e2416"
      },
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFf7sNR84BE_"
      },
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "    \n",
        "    edit_two_set = set()\n",
        "    \n",
        "    edit_one_set = edit_one_letter(word, allow_switches)\n",
        "    one_edit_list = [edit_one_letter(edited_w, allow_switches) for edited_w in edit_one_set]\n",
        "    for i in one_edit_list:\n",
        "        edit_two_set = edit_two_set.union(i)\n",
        "    \n",
        "    return edit_two_set"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8db73bc4BCc",
        "outputId": "1b82170f-c566-4ece-a977-a7dbd3d9191d"
      },
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "The data type of the returned object should be a set <class 'set'>\n",
            "Number of strings that are 2 edit distances from 'at' is 7154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6-CdUgC4A_J"
      },
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "\n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab) or word)\n",
        "    n_best = sorted([(i, probs[i]) for i in list(suggestions)], key = lambda x: -x[1])[:n]\n",
        "    \n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dPMHvFe4A8k",
        "outputId": "095554ae-1eee-4ecd-ff92-6a89641f3aa6"
      },
      "source": [
        "my_word = 'dys' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "print(f\"data type of corrections {type(tmp_corrections)}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  dys \n",
            "suggestions =  ['days', 'dye']\n",
            "word 0: days, probability 0.000410\n",
            "word 1: dye, probability 0.000019\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM0DUSRr41XN"
      },
      "source": [
        "## Minimum Edit distance\n",
        "\n",
        "We need to evaluate the similarity between two strings like 'waht' and 'what' to implement auto-correct with the functionality pieces we coded.\n",
        "And we also need to find an efficient shortest path to go from the word, 'waht' to the word 'what'\n",
        "\n",
        "We need to implement a dynamic programming system that will tell you the minimum number of edits required to convert a string into another string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeaRbBP14A5U"
      },
      "source": [
        "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
        "    \n",
        "    \n",
        "    m = len(source) \n",
        "    n = len(target) \n",
        "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
        "    D = np.zeros((m+1, n+1), dtype=int) \n",
        "    \n",
        "    for row in range(1,m+1):\n",
        "        D[row,0] = row\n",
        "        \n",
        "    for col in range(1,n+1):\n",
        "        D[0,col] = col\n",
        "        \n",
        "    for row in range(1,m+1): \n",
        "        for col in range(1,n+1):\n",
        "            \n",
        "            r_cost = rep_cost\n",
        "            if source[row-1] == target[col-1]:\n",
        "                r_cost = 0\n",
        "            D[row,col] = min(D[row-1, col]+ins_cost, D[row][col-1]+del_cost, D[row-1][col-1]+r_cost)\n",
        "          \n",
        "    # Set the minimum edit distance with the cost found at row m, column n\n",
        "    med = D[m][n]\n",
        "    \n",
        "    return D, med"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPsMXZTv53bN",
        "outputId": "7c47d2b1-dd0c-4683-8a22-5398331ba3ca"
      },
      "source": [
        "source =  'play'\n",
        "target = 'stay'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list('#' + source)\n",
        "cols = list('#' + target)\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum edits:  4 \n",
            "\n",
            "   #  s  t  a  y\n",
            "#  0  1  2  3  4\n",
            "p  1  2  3  4  5\n",
            "l  2  3  4  5  6\n",
            "a  3  4  5  4  5\n",
            "y  4  5  6  5  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sk0g3vf53Yp",
        "outputId": "9dc08729-541f-4cdb-f46e-908c67d1417d"
      },
      "source": [
        "source =  'eer'\n",
        "target = 'near'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list(source)\n",
        "idx.insert(0, '#')\n",
        "cols = list(target)\n",
        "cols.insert(0, '#')\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum edits:  3 \n",
            "\n",
            "   #  n  e  a  r\n",
            "#  0  1  2  3  4\n",
            "e  1  2  1  2  3\n",
            "e  2  3  2  3  4\n",
            "r  3  4  3  4  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8TfvgXD6GNX"
      },
      "source": [
        "## Need to implement backtracking algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ7Alu_053S2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}